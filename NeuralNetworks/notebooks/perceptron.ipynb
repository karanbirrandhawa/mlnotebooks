{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "A perceptron is a basic learning algorithm/model that sits as a pillar of neural network programming. For this notebook when we refer to perceptron we're going to refer to a single-layer perceptron that will operate as follows:\n",
    "\n",
    "- Multiple input nodes will be connected to a node (or multiple nodes) in the next layer. \n",
    "- We can also have a a bias node ${w_0}$\n",
    "- The node(s) in the next layer take a weighted sum of all its inputs: $ \\sum{w_i}{I_i} $\n",
    "- Each of the node(s) in the next layer will have a \"threshold\" ${t}$. It can compare the weighted sum against that threshold and output in binary form: \n",
    "  - $ if \\sum{w_i}{I_i} \\geq {t} $ then $ y = 1 $\n",
    "  - $ if \\sum{w_i}{I_i} \\lt {t} $ then $ y = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAIfCAMAAABaTtrTAAAABGdBTUEAALGPC/xhBQAAACBjSFJN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\nRi0xLjUgBVwLOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='../images/perceptron.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an easy example of a single-layer perceptron to train an AND gate. First let's look at an AND gate's behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Perceptron Algorithm\n",
    "\n",
    "We're going to go through the algorithm for a single-layer perceptron. For a multi-layer perceptron, which has a hidden layer, we'll need to use a more complicated algorithm such as backpropogation. \n",
    "\n",
    "The algorith will require a training data set which will consist of an input ${x}$ with any number of features and  binary desired output for the input ${d}$. i.e. one line could be $x= [1, 0]$, $d = 0$. We will also require a function $ f $ which will produce the output. \n",
    "\n",
    "\\begin{align}\n",
    "f(x) = \\{  \\begin{array} 1 1 \\space if \\space w \\cdot x + b > 0 \\\\ 0 \\space otherwise\\end{array}\n",
    "\\end{align}\n",
    "\n",
    "$ w \\cdot x $ is the dot product between the weights and the input. $ b $ is the bias, and allows us to shift the decision boundary away from the origin. Within the case of this single layer perceptron we use a step activation function. This is useful since we plan to operate on linearly seperable data. Later we're going to be working on multi-layer perceptrons and other variations that deal with data that's not necessarily linear. In that case we would not be able to use this activation function and instead using something such as the sigmoid function. \n",
    "\n",
    "\n",
    "The algorithm witself ill operate as follows:\n",
    "\n",
    "1. Initialize all weights to begin with as really small random values. \n",
    "2. Create a train function which will train the perceptron with the data for each example ${j}$. For each example ${j}$, perform the following steps over the input ${i_j}$ and desired output ${d_j}$:\n",
    "    1. Calculate the actual output using the following hypothesis function:\n",
    "        \\begin{align}\n",
    "        y_j(t) & = f|w(t) \\cdot x_j| \\\\\n",
    "               & = f|{w_0(t)}x_{j,0} + {w_1(t)}x_{j,1} .. + {w_n(t)}x_{j,n}| \n",
    "        \\end{align}\n",
    "    2. Update the weights:\n",
    "        \\begin{align}\n",
    "        w_i(t + 1) & = w_i(t) + (d_j - y_j(t))x_{j,i}\n",
    "        \\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        \"\"\"Initialize perceptron with random, preferably small, weights.\"\"\"\n",
    "        self.w = [random.random() for i in range(input_size)]\n",
    "    \n",
    "    def output(self, x):\n",
    "        \"\"\"Obtain output from perceptron based on input vector \"\"\"\n",
    "        return self.activation(self.w, x)\n",
    "          \n",
    "    def train(self, data):\n",
    "        \"\"\"Train perceptron based on provided data\"\"\"\n",
    "        for j in data:\n",
    "            x = j[:len(j)-1]\n",
    "            d = j[len(j)-1]\n",
    "            \n",
    "            y = self.activation(self.w, x)\n",
    "            self.update_weights(self.w, d, x, y)\n",
    "\n",
    "    def activation(self, w, x):\n",
    "        \"\"\"Activation function for perceptron using step function outlined above\"\"\"\n",
    "        if np.dot(self.w, x) < 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def update_weights(self, w, d, x, y):\n",
    "        \"\"\"Updates weights using function outlined above\"\"\"\n",
    "        for i in range(len(self.w)):\n",
    "            self.w[i] = w[i] + (y - d)*x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import rand, plot, norm, show\n",
    "\n",
    "def generate_data(size):\n",
    "    \"\"\"Generate test data which will essentially just add blue (xb, yb) and red (xr, yr) points to a 2D graph\"\"\"\n",
    "    xb = rand(size)*0.5       # between 0 and 0.5\n",
    "    yb = rand(size)*0.5 + 0.5 # between 0.5 and 1\n",
    "    xr = rand(size)*0.5 + 0.5 # between 0.5 and 1\n",
    "    yr = rand(size)*0.5       # between 0 and 0.5\n",
    "    \n",
    "    data = []\n",
    "    for i in range(size):\n",
    "        data.append([xb[i], yb[i], 1])\n",
    "        data.append([xr[i], yr[i], 0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "perceptron = Perceptron(2) # Perceptron with input vector of size 2: (x, y) coords\n",
    "training_data = generate_data(100)\n",
    "perceptron.train(training_data)\n",
    "\n",
    "test_data = generate_data(20)\n",
    "for j in test_data:\n",
    "    input_vector = j[:len(j)-1]\n",
    "    desired_output = j[len(j)-1]\n",
    "    classification = perceptron.output(input_vector)\n",
    "    \n",
    "    if classification == 1:\n",
    "        plot(j[0], j[1], 'ob')\n",
    "    else:\n",
    "        plot(j[0], j[1], 'or')\n",
    "\n",
    "# plot of the separation line.\n",
    "# The separation line is orthogonal to w\n",
    "n = norm(perceptron.w)\n",
    "ww = perceptron.w/n\n",
    "ww1 = [ww[1],-ww[0]]\n",
    "ww2 = [-ww[1],ww[0]]\n",
    "plot([ww1[0], ww2[0]],[ww1[1], ww2[1]],'--k')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron is a linear classifier. A linear classifier, as can be seen from its name, makes a decision on its classification based on a linear combination of its feature values. Thus it will never be able to correctly classify unless the training data set is linearly seperable. In order to get a working perceptron algorithm it's important to ensure that the data is linearly seperable to guarantee convergence. Graphically this would mean ensuring that a straight line could seperate our data into its two classes.\n",
    "\n",
    "One method of testing for linear seperability discussed in later notebooks is constructing a linear SVM and checking if it has 0% error.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
